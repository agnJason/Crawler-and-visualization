{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T02:29:59.079680Z",
     "start_time": "2020-01-11T02:29:59.072676Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\AGN's SP\\OneDrive\\课件\\数据可视化\\期末\\work\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 爬虫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T02:32:06.195583Z",
     "start_time": "2020-01-11T02:30:27.783001Z"
    }
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "browser = webdriver.Chrome()\n",
    "dict_={}\n",
    "for i in range(10):\n",
    "    dict_[i+2009]={}\n",
    "    browser.get('http://bang.dangdang.com/books/bestsellers/01.00.00.00.00.00-year-{}-0-1-1'.format(str(i+2009)))\n",
    "    browser.find_elements\n",
    "    list_ = browser.find_elements_by_xpath(\"/html/body/div[3]/div[3]/div[2]/ul/li\")\n",
    "    for index, l in enumerate(list_):\n",
    "        name = browser.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[2]/ul/li[{}]/div[@class='name']\".format(index+1)).text\n",
    "        #print(name)\n",
    "        comment = browser.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[2]/ul/li[{}]/div[@class='star']\".format(index+1)).text\n",
    "        #print(comment)\n",
    "        author = browser.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[2]/ul/li[{}]/div[5]\".format(index+1)).text\n",
    "        #print(author)\n",
    "        cbs = browser.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[2]/ul/li[{}]/div[6]\".format(index+1)).text\n",
    "        #print(cbs)\n",
    "        price = browser.find_element_by_xpath(\"/html/body/div[3]/div[3]/div[2]/ul/li[{}]/div[@class='price']/p/span\".format(index+1)).text\n",
    "        #print(price)\n",
    "        dict_[i+2009][name]={'author':author,'comment':comment,'price':price, 'cbs':cbs,\\\n",
    "                         'url':browser.find_element_by_partial_link_text(name).get_attribute('href')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T02:32:38.288187Z",
     "start_time": "2020-01-11T02:32:38.237195Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T08:43:11.924220Z",
     "start_time": "2020-01-11T08:43:11.898220Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "books = []\n",
    "for key in dict_.keys():\n",
    "    books.extend(dict_[key].keys())\n",
    "counter = collections.Counter(books)\n",
    "most_20 = counter.most_common(20)\n",
    "dict_20 = {}\n",
    "for common in most_20:\n",
    "    bookname = common[0]\n",
    "    #print(bookname)\n",
    "    dict_20[bookname] = {}\n",
    "    dict_20[bookname]['id'] = None\n",
    "    year = 2009\n",
    "    while dict_20[bookname]['id']==None:\n",
    "        if bookname in dict_[year].keys():\n",
    "            dict_20[bookname]['id']=dict_[year][bookname]['url'].replace('http://product.dangdang.com/','').replace('.html', '')\n",
    "            dict_20[bookname]['comment']=int(dict_[year][bookname]['comment'].split('条')[0])\n",
    "        year += 1\n",
    "dict_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-30T22:41:17.837040Z",
     "start_time": "2019-12-30T13:04:34.276581Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "from bs4 import BeautifulSoup as bs\n",
    "id_ = 20026456\n",
    "page = 1\n",
    "for book in dict_20.keys():\n",
    "    print('-'*100)\n",
    "    print(book,' start!')\n",
    "    dict_20[book]['comments']=[]\n",
    "    id_ = dict_20[book]['id']\n",
    "    headers={\n",
    "            'Host': 'product.dangdang.com',\n",
    "            'Referer': \"http://product.dangdang.com/{}.html\".format(id_),\n",
    "            'User-Agent': \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/75.0.3770.142 Safari/537.36\"\n",
    "        }\n",
    "    response = requests.get(\"http://product.dangdang.com/index.php?r=comment%2Flist&productId={}&\\\n",
    "                                    categoryPath=01.18.10.00.00.00&mainProductId={}&mediumId=0&pageIndex={}&sortType=1&filterType=1\\\n",
    "                                    &isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=short\".format(id_,id_,1), headers=headers)\n",
    "    js = json.loads(response.text)\n",
    "    dict_20[book]['comments_num'] = int(js['data']['list']['summary']['total_comment_num'])\n",
    "    num_page = 1000\n",
    "    if int(dict_20[book]['comments_num']/10)<1000:\n",
    "        num_page = int(dict_20[book]['comments_num']/10)\n",
    "    for page in range(num_page):\n",
    "        print(\"第{}页\".format(page))\n",
    "        page += 1\n",
    "        #comments = []\n",
    "        #times = []\n",
    "        try:\n",
    "            response = requests.get(\"http://product.dangdang.com/index.php?r=comment%2Flist&productId={}&\\\n",
    "                                    categoryPath=01.18.10.00.00.00&mainProductId={}&mediumId=0&pageIndex={}&sortType=1&filterType=1\\\n",
    "                                    &isSystem=1&tagId=0&tagFilterCount=0&template=publish&long_or_short=short\".format(id_,id_,page), headers=headers)\n",
    "            #print(response)\n",
    "            js = json.loads(response.text)\n",
    "            soup = bs(js['data']['list']['html'], 'lxml')\n",
    "\n",
    "            lst = soup.find_all('div', class_='items_right')\n",
    "            for l in lst:\n",
    "                comment = []\n",
    "                for n in l.find_all('span'):\n",
    "                    if ''.join(n.text.split())!='':\n",
    "                        comment.append(n.text)\n",
    "                #comments.append(comment[0])\n",
    "                for m in comment:\n",
    "                    if m[:2]=='20':\n",
    "                        dict_20[book]['comments'].append((comment[0], m))\n",
    "                        #times.append(m)\n",
    "                        break\n",
    "        except:\n",
    "            print(\"第{}页失败\".format(page))\n",
    "        time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-31T02:03:18.429392Z",
     "start_time": "2019-12-31T02:03:17.893353Z"
    }
   },
   "outputs": [],
   "source": [
    "f = open(r\"data\\dict_20.txt\",'w',encoding='utf-8')\n",
    "f.write(str(dict_20))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:58:49.187100Z",
     "start_time": "2020-01-11T10:58:49.178105Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(r\"C:\\Users\\AGN's SP\\OneDrive\\课件\\数据可视化\\期末\\work\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:58:53.394107Z",
     "start_time": "2020-01-11T10:58:50.970083Z"
    }
   },
   "outputs": [],
   "source": [
    "#读取\n",
    "f = open(r\"data\\dict_20.txt\",'r',encoding='utf-8')\n",
    "a = f.read()\n",
    "dict_20 = eval(a)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:58:54.375080Z",
     "start_time": "2020-01-11T10:58:54.357084Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "def time_count(dict_):\n",
    "    comments = dict_['comments']\n",
    "    comments_month = defaultdict(list)\n",
    "    for n in comments:\n",
    "        if len(re.findall('20..-..-',n[1]))==0:\n",
    "            continue\n",
    "        month = n[1][:7].replace('-','')\n",
    "        comments_month[month].append(n[0])\n",
    "    comments_month = sorted(comments_month.items(),key=lambda x:x[0])\n",
    "    return comments_month\n",
    "\n",
    "#dict_ = time_count(dict_20['百年孤独（加西亚马尔克斯代表作）'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T08:49:02.295517Z",
     "start_time": "2020-01-11T08:49:02.266518Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyecharts.charts import Bar\n",
    "import pyecharts.options as opts\n",
    "#import matplotlib.pyplot as plt\n",
    "bar = Bar()#新建柱状图\n",
    "bar.add_xaxis((list(dict_20.keys())).add_yaxis(\"评论数\", [dict_20[name]['comment'] for name in dict_20.keys()])    # 增加y轴\n",
    "bar.set_global_opts(=opts.AxisTickOpts())\n",
    "bar.render('总评论数.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 情感分析 存为csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T16:24:19.235366Z",
     "start_time": "2020-01-09T16:24:16.286Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def dict2csv(dict_):\n",
    "    data = []\n",
    "    index = 0\n",
    "    for bookname in dict_.keys():\n",
    "        for n in dict_[bookname]['comments']:\n",
    "            if len(re.findall('20..-..-',n[1]))!=0 and n[1].strip()!='':\n",
    "                data.append([n[1],bookname,n[0]])\n",
    "    data = pd.DataFrame(data, columns=['日期','书名','评论'])\n",
    "    return data\n",
    "data = dict2csv(dict_20)\n",
    "#data.to_csv(r\"data/book_comments_20.csv\", index=0,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T10:19:54.230284Z",
     "start_time": "2020-01-09T10:19:33.468206Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import snownlp \n",
    "import tqdm\n",
    "def senti(data):\n",
    "    senti_score = []\n",
    "    keywords = []\n",
    "    summary = []\n",
    "    for n in tqdm.tqdm_notebook(data['评论']):\n",
    "        s = snownlp.SnowNLP(n)\n",
    "        senti_score.append(s.sentiments)\n",
    "        keywords.append(' '.join(s.keywords()))\n",
    "        try:\n",
    "            summary.append(s.summary(1)[0])\n",
    "        except:\n",
    "            summary.append('-')\n",
    "    data['情感分数']=senti_scoree\n",
    "    data['关键词']=keywords\n",
    "    data['总结']=summary\n",
    "senti(data)\n",
    "data.to_csv(r\"data/book_comments_20.csv\", index=0,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评论数量折线图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T16:03:28.795602Z",
     "start_time": "2020-01-09T16:03:24.761257Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import *\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import pyecharts.options as opts\n",
    "from example.commons import Collector, Faker\n",
    "from pyecharts.charts import Line, Page\n",
    "\n",
    "def lineDraw(info):\n",
    "    A = Collector()\n",
    "    @A.funcs\n",
    "    def line() -> Line:\n",
    "        date = [n[0] for n in info]\n",
    "        bookname=info[0][1]\n",
    "        comments_num = [n[2] for n in info]\n",
    "        line = (\n",
    "            Line(init_opts=opts.InitOpts(bg_color=\"white\"))\n",
    "            .add_xaxis(date)    # 增加x轴\n",
    "            .add_yaxis(\"评论数\", comments_num, is_smooth=True,\n",
    "                       areastyle_opts=opts.AreaStyleOpts(opacity=0.5))     # 增加y轴\n",
    "            #.add_yaxis(\"情感分数\", senti_score, is_smooth=True,\n",
    "            #           areastyle_opts=opts.AreaStyleOpts(opacity=0.5))\n",
    "            .set_global_opts(\n",
    "                title_opts=opts.TitleOpts(title=bookname, subtitle=\"评论数\"),\n",
    "                xaxis_opts=opts.AxisOpts(\n",
    "                    axistick_opts=opts.AxisTickOpts(is_align_with_label=True),\n",
    "                    is_scale=False,\n",
    "                    boundary_gap=False\n",
    "                ),  # 图像贴近y轴\n",
    "                yaxis_opts=opts.AxisOpts(splitline_opts=opts.SplitLineOpts(is_show=True))   # 增加y轴分割线\n",
    "            )   # 全局配置项\n",
    "            .set_series_opts(\n",
    "                markpoint_opts=opts.MarkPointOpts(\n",
    "                    data=[opts.MarkPointItem(type_=\"max\"), opts.MarkPointItem(type_=\"min\")],\n",
    "                    symbol_size=[34, 30],\n",
    "                    label_opts=opts.LabelOpts(position=\"inside\", color=\"#fff\", font_size=8)\n",
    "                ),\n",
    "                label_opts=opts.LabelOpts(is_show=False),\n",
    "                markline_opts=opts.MarkLineOpts(data=[opts.MarkLineItem(type_=\"average\")])\n",
    "            )   # 系列配置项\n",
    "        )\n",
    "        return line\n",
    "    Page().add(*[fn() for fn, _ in A.charts]).render(u'./line.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:59:02.063450Z",
     "start_time": "2020-01-11T10:59:01.650079Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def show_num_all():\n",
    "    com_num = []\n",
    "    for bookname in dict_20.keys():\n",
    "        lst = []\n",
    "        dict_ = time_count(dict_20[bookname])\n",
    "        comments_month_num = defaultdict(int)\n",
    "        for n in dict_:\n",
    "            lst.append([n[0][0:4]+'-'+n[0][4:6], bookname, len(n[1])])\n",
    "        #lineDraw(lst)    #画line取消注释\n",
    "        com_num.extend(lst)\n",
    "    return com_num\n",
    "com_num = show_num_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:59:03.152085Z",
     "start_time": "2020-01-11T10:59:03.139080Z"
    }
   },
   "outputs": [],
   "source": [
    "date =sorted(list(set([x[0][0:4]+'-'+x[0][4:6] for x in com_num])))\n",
    "bookname = list(set([n[1] for n in com_num]))\n",
    "data = sorted(com_num, key=lambda x:x[0])\n",
    "data= [[x[0][0:4]+'-'+x[0][4:6],x[1],x[2]] for x in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 评论数量3D图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T16:54:19.889183Z",
     "start_time": "2020-01-09T16:54:16.482Z"
    }
   },
   "outputs": [],
   "source": [
    "from example.commons import Collector, Faker\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Bar3D, Page\n",
    "import random\n",
    "C = Collector()\n",
    "@C.funcs\n",
    "def bar3d_base() -> Bar3D:\n",
    "    # data = [(i, j, random.randint(0, 12)) for i in range(6) for j in range(24)]\n",
    "    # print([[d[1], d[0], d[2]] for d in data])\n",
    "    c = (\n",
    "        Bar3D(init_opts=opts.InitOpts(width='1200px', height='1000px'))\n",
    "        .add(\n",
    "            \"\",\n",
    "            data,\n",
    "            xaxis3d_opts=opts.Axis3DOpts(date, type_=\"category\"),\n",
    "            yaxis3d_opts=opts.Axis3DOpts(bookname, type_=\"category\"),\n",
    "            zaxis3d_opts=opts.Axis3DOpts(type_=\"value\"),\n",
    "        )\n",
    "        .set_global_opts(\n",
    "            visualmap_opts=opts.VisualMapOpts(max_=500),\n",
    "            title_opts=opts.TitleOpts(title=\"评论数量3D\"),\n",
    "        )\n",
    "    )\n",
    "    return c\n",
    "\n",
    "p = Page()\n",
    "p.add(*[fn() for fn, _ in C.charts]).render(u'./评论数量3Dbar.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 情感分析饼状图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:59:09.578533Z",
     "start_time": "2020-01-11T10:59:06.870090Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"data/book_comments_20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:59:10.775574Z",
     "start_time": "2020-01-11T10:59:10.753537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>日期</th>\n",
       "      <th>书名</th>\n",
       "      <th>评论</th>\n",
       "      <th>情感分数</th>\n",
       "      <th>关键词</th>\n",
       "      <th>总结</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-02-19 15:21:07</td>\n",
       "      <td>百年孤独（加西亚马尔克斯代表作）</td>\n",
       "      <td>对我而言，单从读《百年孤独》的直观感觉来说，是非常的微妙且有意思的。与以往容易入书...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>孤独 层 良诺 奥雷 总</td>\n",
       "      <td>到最后一个具有家族明显特征的奥雷良诺</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-03-03 13:42:01</td>\n",
       "      <td>百年孤独（加西亚马尔克斯代表作）</td>\n",
       "      <td>第一遍看这本书的时候真的是迷迷糊糊的，一点也看不懂，只是照着情节读了下来，字里行间里就是有一...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>里 看 种 透 印象</td>\n",
       "      <td>一点也看不懂</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-06 22:04:19</td>\n",
       "      <td>百年孤独（加西亚马尔克斯代表作）</td>\n",
       "      <td>《百年孤独》（西班牙语：Cien a?os de soledad），是哥伦比亚作家加夫列尔·...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>百年 年 孤独 拉丁美洲 马尔克斯</td>\n",
       "      <td>”《百年孤独》发表于1967年</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-12-19 21:00:36</td>\n",
       "      <td>百年孤独（加西亚马尔克斯代表作）</td>\n",
       "      <td>《百年孤独》，是哥伦比亚作家加西亚·马尔克斯的代表作，也是拉丁美洲魔幻现实主义文学的代表作...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>家族 历史 人 此书 都</td>\n",
       "      <td>布恩迪亚家族的每个人都渴望得到幸福</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-06-20 19:07:30</td>\n",
       "      <td>百年孤独（加西亚马尔克斯代表作）</td>\n",
       "      <td>整本书简直是一首磅礴华丽的交响乐！\\r作者一开始就营造了长期与世隔绝的小村落所散发的安定却极...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>恩迪亚 布 孤独 家族 却</td>\n",
       "      <td>但最大的孤独感恐怕出于布恩迪亚家族自身</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    日期                书名  \\\n",
       "0  2012-02-19 15:21:07  百年孤独（加西亚马尔克斯代表作）   \n",
       "1  2013-03-03 13:42:01  百年孤独（加西亚马尔克斯代表作）   \n",
       "2  2013-12-06 22:04:19  百年孤独（加西亚马尔克斯代表作）   \n",
       "3  2012-12-19 21:00:36  百年孤独（加西亚马尔克斯代表作）   \n",
       "4  2011-06-20 19:07:30  百年孤独（加西亚马尔克斯代表作）   \n",
       "\n",
       "                                                  评论  情感分数                关键词  \\\n",
       "0       对我而言，单从读《百年孤独》的直观感觉来说，是非常的微妙且有意思的。与以往容易入书...   1.0       孤独 层 良诺 奥雷 总   \n",
       "1  第一遍看这本书的时候真的是迷迷糊糊的，一点也看不懂，只是照着情节读了下来，字里行间里就是有一...   1.0         里 看 种 透 印象   \n",
       "2  《百年孤独》（西班牙语：Cien a?os de soledad），是哥伦比亚作家加夫列尔·...   1.0  百年 年 孤独 拉丁美洲 马尔克斯   \n",
       "3   《百年孤独》，是哥伦比亚作家加西亚·马尔克斯的代表作，也是拉丁美洲魔幻现实主义文学的代表作...   1.0       家族 历史 人 此书 都   \n",
       "4  整本书简直是一首磅礴华丽的交响乐！\\r作者一开始就营造了长期与世隔绝的小村落所散发的安定却极...   1.0      恩迪亚 布 孤独 家族 却   \n",
       "\n",
       "                    总结  \n",
       "0   到最后一个具有家族明显特征的奥雷良诺  \n",
       "1               一点也看不懂  \n",
       "2      ”《百年孤独》发表于1967年  \n",
       "3    布恩迪亚家族的每个人都渴望得到幸福  \n",
       "4  但最大的孤独感恐怕出于布恩迪亚家族自身  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-11T10:59:13.483806Z",
     "start_time": "2020-01-11T10:59:12.293779Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import max, min, mean, quantile, median, percentile\n",
    "\n",
    "from example.commons import Collector, Faker\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Page, Pie\n",
    "\n",
    "def pie(data, bookname):\n",
    "    C = Collector()\n",
    "    @C.funcs\n",
    "    def pie_rosetype() -> Pie:\n",
    "        c = (\n",
    "            Pie()\n",
    "            .add('', data,\n",
    "            label_opts=opts.LabelOpts(is_show=True),)\n",
    "            .set_global_opts(title_opts=opts.TitleOpts(title=bookname,subtitle='情感分布'))\n",
    "        )\n",
    "        return c\n",
    "    Page().add(*[fn() for fn, _ in C.charts]).render(u'./pie-情感分析.html')\n",
    "\n",
    "def senti_score_show(dftotal):\n",
    "    for name in bookname:\n",
    "        #print(name)\n",
    "        df = dftotal[dftotal['书名']==name]\n",
    "        #  winsorize 去除极端值\n",
    "        q5 = df.quantile(0.05)['情感分数']\n",
    "        q95 = df.quantile(0.95)['情感分数']\n",
    "        # print(df_weibo.quantile(0.95)['情感得分'])\n",
    "        senti_list = []\n",
    "        for i in df['情感分数']:\n",
    "            if (i <= q95) and (i >= q5):\n",
    "                senti_list.append(i)\n",
    "\n",
    "        senti_dict = {}\n",
    "        # 分位数统计，统计结果有用于人工将情感得分划分出区间\n",
    "        senti_max = max(senti_list)\n",
    "        senti_min = min(senti_list)\n",
    "        senti_mean = mean(senti_list)\n",
    "        senti_25 = (senti_mean - senti_min) / 2\n",
    "        senti_75 = (senti_max - senti_mean) / 2\n",
    "        #print(senti_max, senti_min, senti_mean, senti_25, senti_75)\n",
    "        senti_dict['极端负面情感']=0\n",
    "        senti_dict['负面情感']=0\n",
    "        senti_dict['中性情感']=0\n",
    "        senti_dict['正向情感']=0\n",
    "        senti_dict['极端正向情感']=0\n",
    "        for i in senti_list:\n",
    "            if i < 0.1:\n",
    "                senti_dict['极端负面情感'] = senti_dict.get(\"极端负面情感\", 0) + 1\n",
    "            elif 0.1 <= i < 0.4:\n",
    "                senti_dict['负面情感'] = senti_dict.get(\"负面情感\", 0) + 1\n",
    "            elif 0.4 <= i < 0.6:\n",
    "                senti_dict['中性情感'] = senti_dict.get(\"中性情感\", 0) + 1\n",
    "            elif 0.6 <= i < 0.9:\n",
    "                senti_dict['正向情感'] = senti_dict.get(\"正向情感\", 0) + 1\n",
    "            elif 0.9 <= i:\n",
    "                senti_dict['极端正向情感'] = senti_dict.get(\"极端正向情感\", 0) + 1\n",
    "\n",
    "        data = []\n",
    "        for k, v in senti_dict.items():\n",
    "            data1 = []\n",
    "            data1.append(k)\n",
    "            data1.append(v)\n",
    "            data.append(data1)\n",
    "        #print(data)\n",
    "        pie(data,name)\n",
    "\n",
    "senti_score_show(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 情感分析3D图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T17:52:50.826444Z",
     "start_time": "2020-01-09T17:50:28.885551Z"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "df['日期'] = df['日期'].apply(lambda x:x[:7])\n",
    "date_month = sorted(list(set([n for n in df['日期']])))\n",
    "senscore = []\n",
    "for name in tqdm.tqdm_notebook(bookname):\n",
    "    for month in date_month:\n",
    "        ddf = df[df['书名']==name][df['日期']==month]['情感分数']\n",
    "        try:\n",
    "            senscore.append([month, name, sum(ddf)/len(ddf)])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T17:53:08.423212Z",
     "start_time": "2020-01-09T17:53:08.416225Z"
    }
   },
   "outputs": [],
   "source": [
    "senscore[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-09T17:53:23.752954Z",
     "start_time": "2020-01-09T17:53:23.526957Z"
    }
   },
   "outputs": [],
   "source": [
    "from example.commons import Collector, Faker\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Bar3D, Page\n",
    "import random\n",
    "C = Collector()\n",
    "@C.funcs\n",
    "def bar3d_base() -> Bar3D:\n",
    "    # data = [(i, j, random.randint(0, 12)) for i in range(6) for j in range(24)]\n",
    "    # print([[d[1], d[0], d[2]] for d in data])\n",
    "    c = (\n",
    "        Bar3D(init_opts=opts.InitOpts(width='1200px', height='1000px'))\n",
    "        .add(\n",
    "            \"\",\n",
    "            senscore,\n",
    "            xaxis3d_opts=opts.Axis3DOpts(date_month, type_=\"category\"),\n",
    "            yaxis3d_opts=opts.Axis3DOpts(bookname, type_=\"category\"),\n",
    "            zaxis3d_opts=opts.Axis3DOpts(type_=\"value\"),\n",
    "        )\n",
    "        .set_global_opts(\n",
    "            visualmap_opts=opts.VisualMapOpts(max_=1),\n",
    "            title_opts=opts.TitleOpts(title=\"情感分数3D\"),\n",
    "        )\n",
    "    )\n",
    "    return c\n",
    "\n",
    "p = Page()\n",
    "p.add(*[fn() for fn, _ in C.charts]).render(u'./情感分数3Dbar.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关键词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T03:28:26.622854Z",
     "start_time": "2020-01-10T03:28:00.514567Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "def getstopword(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        stopword = [line.strip('\\n') for line in f.readlines()]\n",
    "        stopword.append(' ')\n",
    "        stopword.append('\\xa0')\n",
    "        stopword.append('\\n')\n",
    "        stopword.append('\\t')\n",
    "    return list(set(stopword))\n",
    "stopword_path = r\"stopwords.txt\"\n",
    "stopwords = getstopword(stopword_path)\n",
    "\n",
    "book_keywords_20 = []\n",
    "for name in bookname:\n",
    "    key = df['关键词'][df['书名']==name]\n",
    "    keywords = []\n",
    "    for n in key:\n",
    "        #print(n)\n",
    "        try:\n",
    "            keywords.extend([n for n in n.split() if n not in stopwords])\n",
    "        except:\n",
    "            True\n",
    "    count = collections.Counter(keywords)\n",
    "    keywords_20 = []\n",
    "    keywords_20.append(name)\n",
    "    keywords_20.extend([n[0] for n in count.most_common(20)])\n",
    "    book_keywords_20.append(keywords_20)\n",
    "    #print(name, count.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T03:28:58.262194Z",
     "start_time": "2020-01-10T03:28:58.253799Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = ['书名']\n",
    "columns.extend(['第{}个关键词'.format(m+1)for m in range(20)])\n",
    "df_keywords_20 = pd.DataFrame(book_keywords_20, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T03:29:25.179801Z",
     "start_time": "2020-01-10T03:29:25.166803Z"
    }
   },
   "outputs": [],
   "source": [
    "df_keywords_20.to_csv('keywords_20.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关键词知识图谱构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T04:00:49.122229Z",
     "start_time": "2020-01-10T04:00:48.330898Z"
    }
   },
   "outputs": [],
   "source": [
    "from py2neo import Graph,Node, Relationship,NodeMatcher\n",
    "g = Graph(host=\"127.0.0.1\",  # neo4j 搭载服务器的ip地址，ifconfig可获取到\n",
    "            http_port=7474,  # neo4j 服务器监听的端口号\n",
    "            user=\"neo4j\",  # 数据库user name，如果没有更改过，应该是neo4j\n",
    "            password=\"140801\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T04:07:01.290673Z",
     "start_time": "2020-01-10T04:07:01.283718Z"
    }
   },
   "outputs": [],
   "source": [
    "bookname = list(set(df_keywords_20['书名']))\n",
    "keywords = []\n",
    "for n in range(20):\n",
    "    keywords.extend(df_keywords_20['第{}个关键词'.format(n+1)])\n",
    "keywords = list(set(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-10T12:43:14.778522Z",
     "start_time": "2020-01-10T12:43:11.010134Z"
    }
   },
   "outputs": [],
   "source": [
    "for keyword in keywords:\n",
    "    if keyword in bookname:\n",
    "        continue\n",
    "    node = Node(keyword, value=keyword, name=keyword,type_='keyword')\n",
    "    g.create(node)\n",
    "for i, name in enumerate(bookname):\n",
    "    node = Node(name, value=name, name=name, type_='book')\n",
    "    g.create(node) \n",
    "    for n in range(10):\n",
    "        word = df_keywords_20[df_keywords_20['书名']==name]['第{}个关键词'.format(n+1)].iloc[0]\n",
    "        if name!=word:\n",
    "            query = \"match(p),(q) where p.name='%s'and q.value='%s' create (q)-[rel:%s{name:'%s'}]->(p)\" % (\n",
    "                           name, word, 'comments', 'keyword{}'.format(n+1))\n",
    "            g.run(query)\n",
    "g.run(\"MATCH (n) where n.type_='book' RETURN n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
